#!/bin/bash
#SBATCH --job-name=tomato_em
#SBATCH --nodes=1 
#SBATCH --ntasks=1 
#SBATCH --mem=30G
#SBATCH --time=36:00:00
#SBATCH --output=/labs/kamaleswaranlab/MODS/EliteDataHacks/sepy/new_sepy_mehak/out/em_encounter_%A_%a.out
#SBATCH --error=/labs/kamaleswaranlab/MODS/EliteDataHacks/sepy/new_sepy_mehak/out/em_encounter_%A_%a.err
#SBATCH --array=0-10

# This is the list of years to process; each core will take a fraction of each year
YEARS=(2021)

### These are variables passed into the Python Script ###
# Total num of cores assigned to job (i.e. 16)
NUM_OF_PROCESSES=$SLURM_ARRAY_TASK_COUNT

# list of csn and the associated year
CSN_LIST=/labs/kamaleswaranlab/MODS/EliteDataHacks/pt_lists/pt_list_2021_try.psv

#CSN_LIST=/home/cjosef/3.EliteDataHacks/pt_lists/pt_list_2021.psv

# path for yearly pickles
PICKLE_PATH=/labs/kamaleswaranlab/MODS/Yearly_Pickles/HolderSuperTables/
#PICKLE_PATH=/home/cjosef/6.Yearly_Pickles/

# place to write encounter pickles
OUTPUT_PATH=/labs/kamaleswaranlab/MODS/Encounter_Pickles/emHolder_OutlierCorrected/

### Print basic job info to log file for quality check ###
echo The array number is- $SLURM_ARRAY_TASK_ID
echo This is the csn list- $CSN_LIST
echo This is the pickle path- $PICKLE_PATH
echo This is the output path- $OUTPUT_PATH
echo This is the num processes - $NUM_OF_PROCESSES

## Activate the custom python environment
#source /labs/kamaleswaranlab/MODS/Environments/CSJ_env/bin/activate
#source /home/cjosef/environments/csj_env/bin/activate
source /home/maror24/anaconda3/bin/activate monai

python --version

#### FOR LOOP: takes each year and divides the patients in chunks based on number of cores ###
for year in ${YEARS[*]}
do
echo Currently processing year: $year

python /labs/kamaleswaranlab/MODS/EliteDataHacks/sepy/new_sepy_mehak/em_make_dicts_Holder.py $CSN_LIST $PICKLE_PATH $OUTPUT_PATH $NUM_OF_PROCESSES $SLURM_ARRAY_TASK_ID $year

done
